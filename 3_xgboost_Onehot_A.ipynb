{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onehot_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T19:23:16.638836Z",
     "start_time": "2018-06-06T19:23:08.175150Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# filelist: \n",
    "#         train:40428967,  \n",
    "#     minitrain:4042898,  \n",
    "# miniminitrain:404291,  \n",
    "#    test_click:4577464\n",
    "#  \n",
    "\n",
    "#import os\n",
    "#os.chdir('/media/zhou/0004DD1700005FE8/AI/00/project_2/')\n",
    "#os.chdir('E:/AI/00/project_2')\n",
    "\n",
    "\n",
    "class flags(object):\n",
    "    def __init__(self, file_name, onehot_cat):\n",
    "        self.file_name = file_name\n",
    "        self.onehot_cat = onehot_cat\n",
    "        self.data_dir = '../data/project_2/data/{0}/'.format(self.onehot_cat)\n",
    "        self.output_dir = '../data/project_2/output/{0}/'.format(self.onehot_cat)\n",
    "        self.model_dir = '../data/project_2/models/{0}/'.format(self.onehot_cat)\n",
    "\n",
    "class params(object):\n",
    "    def __init__(self, onehot_name):\n",
    "        self.threshold = 10\n",
    "        self.chunksize = 1e3\n",
    "        self.num_trees = 50\n",
    "        self.deep = 15\n",
    "        self.split = '='\n",
    "        # ['A_cat', 'A_hour', 'A_xgb', \n",
    "        #  'B_cat', 'C_his']\n",
    "        self.onehot_name = onehot_name\n",
    "        self.lr_C = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import scipy.sparse as ss\n",
    "#from  sklearn.cross_validation  import  train_test_split \n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score,log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MergeNpz(output_path, file_name, data_begin, threshold=10,):\n",
    "    \"\"\"把生成的多个.npz合并成一个文件并保存\"\"\"\n",
    "    #导入从0开始的文件, 为下面的合并做准备\n",
    "    X_train = ss.load_npz(output_path+'{0}_X_more{1}_begin{2}.npz'.format(file_name, threshold, data_begin[0]),)\n",
    "    y_train = ss.load_npz(output_path+'{0}_y_more{1}_begin{2}.npz'.format(file_name, threshold, data_begin[0]),)\n",
    "    \n",
    "    for begin in range(1,len(data_begin)): #循环读入文件\n",
    "        #文件暂存\n",
    "        X_train_tmp = ss.load_npz(output_path+'{0}_X_more{1}_begin{2}.npz'.format(\n",
    "                                    file_name, threshold, data_begin[begin]),)\n",
    "        y_train_tmp = ss.load_npz(output_path+'{0}_y_more{1}_begin{2}.npz'.format(\n",
    "                                    file_name, threshold, data_begin[begin]),)\n",
    "        X_train = ss.vstack((X_train, X_train_tmp))  #与原有 行稀疏矩阵 进行 行连接\n",
    "        y_train = ss.hstack((y_train, y_train_tmp))  #与原有 列稀疏矩阵 进行 列连接\n",
    "    \n",
    "    print('total shape: ',X_train.shape, ' | ', y_train.shape)\n",
    "    #保存最终连接完成的稀疏矩阵\n",
    "    #ss.save_npz(output_path+'{0}_X_more{1}'.format(file_name, threshold), X_train)\n",
    "    #ss.save_npz(output_path+'{0}_y_more{1}'.format(file_name, threshold), y_train)\n",
    "    #print('saved in {0}'.format(output_path))\n",
    "    return X_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T19:30:46.974660Z",
     "start_time": "2018-06-06T19:30:46.961701Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LogLoss(bst_train, xgtrain):\n",
    "    train_preds = bst_train.predict(xgtrain)\n",
    "    train_predictions = [round(value) for value in train_preds]\n",
    "    y_train = xgtrain.get_label()\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "    train_log_loss = log_loss(y_train, train_preds)\n",
    "    print (\"Train log_loss: \" , train_log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T19:23:17.947652Z",
     "start_time": "2018-06-06T19:23:17.938683Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalsize = {'minitrain':4042898, 'test_click':4577464}\n",
    "file_size = totalsize[FLAGS.file_name]  #总的数据量\n",
    "block_size = 100000  #数据块大小\n",
    "\n",
    "#定义参数\n",
    "data_path = FLAGS.data_dir  # + '../data/project_2/'\n",
    "file_name = FLAGS.file_name\n",
    "chunksize = 1000\n",
    "threshold = 10\n",
    "output_path = FLAGS.output_dir\n",
    "model_path = FLAGS.model_dir\n",
    "\n",
    "data_begins = [i for i in range(0,file_size,block_size)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读入数据并转为xgb.DMatrix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 把生成好的.npz全部合并可以选择部分合并, \n",
    "# 把要合并的begin 放到 list(data_begins)中, \n",
    "# 如[0,200000,900000]做val, [100000,300000, . . . ]做训练, \n",
    "X_train, y_train = MergeNpz(output_path, file_name, data_begins[:-5], threshold,)\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "X_val, y_val = MergeNpz(output_path, file_name, data_begins[-5:], threshold,)\n",
    "y_val = y_val.toarray().astype(np.float32)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n"
     ]
    }
   ],
   "source": [
    "#导入数据\n",
    "threshold = 'A_cat'\n",
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, threshold), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, threshold), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(X_train, label = y_train,)\n",
    "xgtest = xgtrain.slice(range(3500000, 4042898))\n",
    "xgtrain = xgtrain.slice(range(3500000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500000, 542898)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgtrain.num_row(), xgtest.num_row(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4042898, 645142) (4042898,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "#print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test = ss.load_npz(data_path+'minitest_X_more10.npz', )\n",
    "y_test = ss.load_npz(data_path+'minitest_y_more10.npz', )\n",
    "y_test = y_test.toarray().astype(np.float32)[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#weights = np.ones(len(y_train))\n",
    "xgtrain = xgb.DMatrix(X_train, label = y_train,)#weight=weights)\n",
    "xgtest = xgb.DMatrix(X_val, label = y_val,)#weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watchlist=[(xgtrain,'train'), (xgtest,'eval')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = flags('minitrain', 'Onehot_A')\n",
    "PARAMS = params('A_cat')  \n",
    "\n",
    "file_name = FLAGS.file_name\n",
    "onehot_name = PARAMS.onehot_name\n",
    "output_path = FLAGS.output_dir\n",
    "model_path = FLAGS.model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n"
     ]
    }
   ],
   "source": [
    "#导入数据\n",
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(X_train, label = y_train,)\n",
    "xgtest = xgtrain.slice(range(3500000, 4042898))\n",
    "xgtrain = xgtrain.slice(range(3500000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgtrain.num_row(), xgtest.num_row(),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "watchlist=[(xgtrain,'train'), (xgtest,'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training . . . \n",
      "cost time:249\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <th>test-logloss-std</th>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <th>train-logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.399262</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.397840</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.399185</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.397733</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.399117</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.397650</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.399002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.397494</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.398929</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.397403</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.398863</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.397331</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.398783</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.397233</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.398721</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.397144</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.398659</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.397053</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.398611</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.396990</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test-logloss-mean  test-logloss-std  train-logloss-mean  train-logloss-std\n",
       "30           0.399262          0.000037            0.397840           0.000183\n",
       "31           0.399185          0.000025            0.397733           0.000183\n",
       "32           0.399117          0.000042            0.397650           0.000189\n",
       "33           0.399002          0.000007            0.397494           0.000140\n",
       "34           0.398929          0.000035            0.397403           0.000121\n",
       "35           0.398863          0.000046            0.397331           0.000105\n",
       "36           0.398783          0.000105            0.397233           0.000068\n",
       "37           0.398721          0.000109            0.397144           0.000066\n",
       "38           0.398659          0.000114            0.397053           0.000048\n",
       "39           0.398611          0.000101            0.396990           0.000072"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#设置参数, 开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "\n",
    "param = dict(\n",
    "        learning_rate =0.8, \n",
    "        booster='gbtree',\n",
    "        n_estimators=100,  \n",
    "        max_depth=12, \n",
    "        min_child_weight=50,\n",
    "        gamma=0,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        colsample_bylevel=0.7,\n",
    "        objective= 'binary:logistic' ,\n",
    "        eta=0.4,\n",
    "        silent=0,\n",
    "        eval_metric='logloss',\n",
    "        seed=3)\n",
    "\n",
    "\n",
    "num_trees = 40 #树的数量##################\n",
    "\n",
    "#调用cv函数\n",
    "bst_train = xgb.cv(param, xgtrain, num_trees, nfold=3, stratified=True)\n",
    "#bst_train = xgb.train(param, xgtrain, num_trees, ) \n",
    "#new_feature = bst_train.predict(xgtrain, pred_leaf=True)\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "bst_train[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.451957\teval-logloss:0.450707\n",
      "[1]\ttrain-logloss:0.419697\teval-logloss:0.419285\n",
      "[2]\ttrain-logloss:0.412605\teval-logloss:0.413671\n",
      "[3]\ttrain-logloss:0.40737\teval-logloss:0.40987\n",
      "[4]\ttrain-logloss:0.405732\teval-logloss:0.408914\n",
      "[5]\ttrain-logloss:0.404834\teval-logloss:0.408147\n",
      "[6]\ttrain-logloss:0.404127\teval-logloss:0.407441\n",
      "[7]\ttrain-logloss:0.403617\teval-logloss:0.406664\n",
      "[8]\ttrain-logloss:0.403026\teval-logloss:0.406478\n",
      "[9]\ttrain-logloss:0.402047\teval-logloss:0.405182\n",
      "[10]\ttrain-logloss:0.401572\teval-logloss:0.404795\n",
      "[11]\ttrain-logloss:0.401107\teval-logloss:0.404507\n",
      "[12]\ttrain-logloss:0.400748\teval-logloss:0.404357\n",
      "[13]\ttrain-logloss:0.400519\teval-logloss:0.404257\n",
      "[14]\ttrain-logloss:0.400247\teval-logloss:0.404105\n",
      "[15]\ttrain-logloss:0.400011\teval-logloss:0.404001\n",
      "[16]\ttrain-logloss:0.399758\teval-logloss:0.403744\n",
      "[17]\ttrain-logloss:0.399588\teval-logloss:0.404201\n",
      "[18]\ttrain-logloss:0.399253\teval-logloss:0.403879\n",
      "[19]\ttrain-logloss:0.399077\teval-logloss:0.403766\n",
      "[20]\ttrain-logloss:0.398953\teval-logloss:0.403687\n",
      "[21]\ttrain-logloss:0.3987\teval-logloss:0.403495\n",
      "[22]\ttrain-logloss:0.398486\teval-logloss:0.403322\n",
      "[23]\ttrain-logloss:0.398329\teval-logloss:0.403054\n",
      "[24]\ttrain-logloss:0.398234\teval-logloss:0.40292\n",
      "[25]\ttrain-logloss:0.398112\teval-logloss:0.402519\n",
      "[26]\ttrain-logloss:0.397945\teval-logloss:0.402461\n",
      "[27]\ttrain-logloss:0.39785\teval-logloss:0.402372\n",
      "[28]\ttrain-logloss:0.397719\teval-logloss:0.402213\n",
      "[29]\ttrain-logloss:0.397598\teval-logloss:0.402173\n",
      "[30]\ttrain-logloss:0.397494\teval-logloss:0.401931\n",
      "[31]\ttrain-logloss:0.397413\teval-logloss:0.401897\n",
      "[32]\ttrain-logloss:0.397297\teval-logloss:0.401663\n",
      "[33]\ttrain-logloss:0.397195\teval-logloss:0.401617\n",
      "[34]\ttrain-logloss:0.397139\teval-logloss:0.401557\n",
      "[35]\ttrain-logloss:0.397071\teval-logloss:0.401509\n",
      "[36]\ttrain-logloss:0.396999\teval-logloss:0.401433\n",
      "[37]\ttrain-logloss:0.396898\teval-logloss:0.401381\n",
      "[38]\ttrain-logloss:0.396832\teval-logloss:0.401361\n",
      "[39]\ttrain-logloss:0.396782\teval-logloss:0.401325\n"
     ]
    }
   ],
   "source": [
    "bst_train = xgb.train(param, xgtrain, num_trees, evals=watchlist) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n"
     ]
    }
   ],
   "source": [
    "#导入数据\n",
    "threshold = 'A_hour'\n",
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, threshold), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, threshold), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(X_train, label = y_train,)\n",
    "xgtest = xgtrain.slice(range(3500000, 4042898))\n",
    "xgtrain = xgtrain.slice(range(3500000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500000, 542898)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgtrain.num_row(), xgtest.num_row(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watchlist=[(xgtrain,'train'), (xgtest,'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training . . . \n",
      "cost time:79\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <th>test-logloss-std</th>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <th>train-logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.455346</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.455272</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.455350</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.455272</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.455352</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.455272</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.455351</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.455273</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.455352</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.455272</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.455351</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.455272</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.455352</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.455272</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.455350</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.455272</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.455350</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.455273</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.455349</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.455272</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test-logloss-mean  test-logloss-std  train-logloss-mean  train-logloss-std\n",
       "30           0.455346          0.000048            0.455272           0.000024\n",
       "31           0.455350          0.000048            0.455272           0.000024\n",
       "32           0.455352          0.000051            0.455272           0.000024\n",
       "33           0.455351          0.000050            0.455273           0.000024\n",
       "34           0.455352          0.000050            0.455272           0.000024\n",
       "35           0.455351          0.000050            0.455272           0.000024\n",
       "36           0.455352          0.000049            0.455272           0.000024\n",
       "37           0.455350          0.000050            0.455272           0.000024\n",
       "38           0.455350          0.000049            0.455273           0.000024\n",
       "39           0.455349          0.000048            0.455272           0.000024"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#设置参数, 开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "\n",
    "param = dict(\n",
    "        learning_rate =0.8, \n",
    "        booster='gbtree',\n",
    "        n_estimators=100,  \n",
    "        max_depth=12, \n",
    "        min_child_weight=50,\n",
    "        gamma=0,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        colsample_bylevel=0.7,\n",
    "        objective= 'binary:logistic' ,\n",
    "        eta=0.4,\n",
    "        silent=0,\n",
    "        eval_metric='logloss',\n",
    "        seed=3)\n",
    "\n",
    "\n",
    "num_trees = 40 #树的数量##################\n",
    "\n",
    "#调用cv函数\n",
    "bst_train = xgb.cv(param, xgtrain, num_trees, nfold=3, stratified=True)\n",
    "#bst_train = xgb.train(param, xgtrain, num_trees, ) \n",
    "#new_feature = bst_train.predict(xgtrain, pred_leaf=True)\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "bst_train[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.477905\teval-logloss:0.479359\n",
      "[1]\ttrain-logloss:0.457336\teval-logloss:0.456814\n",
      "[2]\ttrain-logloss:0.455432\teval-logloss:0.454008\n",
      "[3]\ttrain-logloss:0.455307\teval-logloss:0.453519\n",
      "[4]\ttrain-logloss:0.455293\teval-logloss:0.453483\n",
      "[5]\ttrain-logloss:0.455287\teval-logloss:0.453407\n",
      "[6]\ttrain-logloss:0.455285\teval-logloss:0.453444\n",
      "[7]\ttrain-logloss:0.455284\teval-logloss:0.453395\n",
      "[8]\ttrain-logloss:0.455284\teval-logloss:0.453419\n",
      "[9]\ttrain-logloss:0.455284\teval-logloss:0.453413\n",
      "[10]\ttrain-logloss:0.455284\teval-logloss:0.453445\n",
      "[11]\ttrain-logloss:0.455284\teval-logloss:0.453435\n",
      "[12]\ttrain-logloss:0.455284\teval-logloss:0.453433\n",
      "[13]\ttrain-logloss:0.455284\teval-logloss:0.453443\n",
      "[14]\ttrain-logloss:0.455284\teval-logloss:0.453465\n",
      "[15]\ttrain-logloss:0.455284\teval-logloss:0.453423\n",
      "[16]\ttrain-logloss:0.455284\teval-logloss:0.453413\n",
      "[17]\ttrain-logloss:0.455284\teval-logloss:0.453421\n",
      "[18]\ttrain-logloss:0.455284\teval-logloss:0.453466\n",
      "[19]\ttrain-logloss:0.455284\teval-logloss:0.453418\n",
      "[20]\ttrain-logloss:0.455284\teval-logloss:0.453437\n",
      "[21]\ttrain-logloss:0.455284\teval-logloss:0.453443\n",
      "[22]\ttrain-logloss:0.455284\teval-logloss:0.453491\n",
      "[23]\ttrain-logloss:0.455284\teval-logloss:0.453499\n",
      "[24]\ttrain-logloss:0.455284\teval-logloss:0.453462\n",
      "[25]\ttrain-logloss:0.455284\teval-logloss:0.453468\n",
      "[26]\ttrain-logloss:0.455284\teval-logloss:0.45344\n",
      "[27]\ttrain-logloss:0.455284\teval-logloss:0.453442\n",
      "[28]\ttrain-logloss:0.455284\teval-logloss:0.453461\n",
      "[29]\ttrain-logloss:0.455284\teval-logloss:0.453419\n",
      "[30]\ttrain-logloss:0.455284\teval-logloss:0.453461\n",
      "[31]\ttrain-logloss:0.455284\teval-logloss:0.45342\n",
      "[32]\ttrain-logloss:0.455284\teval-logloss:0.45344\n",
      "[33]\ttrain-logloss:0.455284\teval-logloss:0.45344\n",
      "[34]\ttrain-logloss:0.455284\teval-logloss:0.453456\n",
      "[35]\ttrain-logloss:0.455284\teval-logloss:0.453424\n",
      "[36]\ttrain-logloss:0.455284\teval-logloss:0.4534\n",
      "[37]\ttrain-logloss:0.455284\teval-logloss:0.453458\n",
      "[38]\ttrain-logloss:0.455284\teval-logloss:0.453449\n",
      "[39]\ttrain-logloss:0.455284\teval-logloss:0.453356\n"
     ]
    }
   ],
   "source": [
    "bst_train = xgb.train(param, xgtrain, num_trees, evals=watchlist) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n"
     ]
    }
   ],
   "source": [
    "#导入数据\n",
    "threshold = 'A_xgb'\n",
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, threshold), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, threshold), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(X_train, label = y_train,)\n",
    "xgtest = xgtrain.slice(range(3500000, 4042898))\n",
    "xgtrain = xgtrain.slice(range(3500000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500000, 542898)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgtrain.num_row(), xgtest.num_row(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watchlist=[(xgtrain,'train'), (xgtest,'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training . . . \n",
      "cost time:241\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <th>test-logloss-std</th>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <th>train-logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.454386</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.454181</td>\n",
       "      <td>0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.420969</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.420669</td>\n",
       "      <td>0.001060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.412808</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.412364</td>\n",
       "      <td>0.000644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.409807</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.409321</td>\n",
       "      <td>0.000798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.407287</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.406712</td>\n",
       "      <td>0.000568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.406366</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.405744</td>\n",
       "      <td>0.000558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.405396</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.404741</td>\n",
       "      <td>0.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.404684</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.403983</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.404063</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.403265</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.403475</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.402651</td>\n",
       "      <td>0.000390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.402966</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.402117</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.402613</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.401718</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.402324</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.401407</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.402021</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.401104</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.401802</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.400844</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.401533</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.400553</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.401225</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.400221</td>\n",
       "      <td>0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.401064</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.400039</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.400842</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.399806</td>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.400672</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.399607</td>\n",
       "      <td>0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.400399</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.399332</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.400188</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.399062</td>\n",
       "      <td>0.000228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.400026</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.398872</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.399931</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.398755</td>\n",
       "      <td>0.000265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.399797</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.398595</td>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.399669</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.398443</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.399561</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.398301</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.399500</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.398196</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.399414</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.398069</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.399336</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.397956</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.399262</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.397840</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.399185</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.397733</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.399117</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.397650</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.399002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.397494</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.398929</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.397403</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.398863</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.397331</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.398783</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.397233</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.398721</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.397144</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.398659</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.397053</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.398611</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.396990</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test-logloss-mean  test-logloss-std  train-logloss-mean  train-logloss-std\n",
       "0            0.454386          0.002213            0.454181           0.002200\n",
       "1            0.420969          0.001043            0.420669           0.001060\n",
       "2            0.412808          0.000596            0.412364           0.000644\n",
       "3            0.409807          0.000742            0.409321           0.000798\n",
       "4            0.407287          0.000494            0.406712           0.000568\n",
       "5            0.406366          0.000514            0.405744           0.000558\n",
       "6            0.405396          0.000553            0.404741           0.000590\n",
       "7            0.404684          0.000429            0.403983           0.000465\n",
       "8            0.404063          0.000321            0.403265           0.000375\n",
       "9            0.403475          0.000315            0.402651           0.000390\n",
       "10           0.402966          0.000212            0.402117           0.000299\n",
       "11           0.402613          0.000134            0.401718           0.000229\n",
       "12           0.402324          0.000102            0.401407           0.000215\n",
       "13           0.402021          0.000130            0.401104           0.000257\n",
       "14           0.401802          0.000168            0.400844           0.000289\n",
       "15           0.401533          0.000185            0.400553           0.000312\n",
       "16           0.401225          0.000120            0.400221           0.000246\n",
       "17           0.401064          0.000126            0.400039           0.000237\n",
       "18           0.400842          0.000088            0.399806           0.000199\n",
       "19           0.400672          0.000059            0.399607           0.000177\n",
       "20           0.400399          0.000067            0.399332           0.000141\n",
       "21           0.400188          0.000099            0.399062           0.000228\n",
       "22           0.400026          0.000121            0.398872           0.000260\n",
       "23           0.399931          0.000137            0.398755           0.000265\n",
       "24           0.399797          0.000130            0.398595           0.000243\n",
       "25           0.399669          0.000101            0.398443           0.000223\n",
       "26           0.399561          0.000070            0.398301           0.000183\n",
       "27           0.399500          0.000054            0.398196           0.000171\n",
       "28           0.399414          0.000048            0.398069           0.000162\n",
       "29           0.399336          0.000044            0.397956           0.000148\n",
       "30           0.399262          0.000037            0.397840           0.000183\n",
       "31           0.399185          0.000025            0.397733           0.000183\n",
       "32           0.399117          0.000042            0.397650           0.000189\n",
       "33           0.399002          0.000007            0.397494           0.000140\n",
       "34           0.398929          0.000035            0.397403           0.000121\n",
       "35           0.398863          0.000046            0.397331           0.000105\n",
       "36           0.398783          0.000105            0.397233           0.000068\n",
       "37           0.398721          0.000109            0.397144           0.000066\n",
       "38           0.398659          0.000114            0.397053           0.000048\n",
       "39           0.398611          0.000101            0.396990           0.000072"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#设置参数, 开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "\n",
    "param = dict(\n",
    "        learning_rate =0.8, \n",
    "        booster='gbtree',\n",
    "        n_estimators=100,  \n",
    "        max_depth=12, \n",
    "        min_child_weight=50,\n",
    "        gamma=0,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        colsample_bylevel=0.7,\n",
    "        objective= 'binary:logistic' ,\n",
    "        eta=0.4,\n",
    "        silent=0,\n",
    "        eval_metric='logloss',\n",
    "        seed=3)\n",
    "\n",
    "\n",
    "num_trees = 40 #树的数量##################\n",
    "\n",
    "#调用cv函数\n",
    "bst_train = xgb.cv(param, xgtrain, num_trees, nfold=3, stratified=True)\n",
    "#bst_train = xgb.train(param, xgtrain, num_trees, ) \n",
    "#new_feature = bst_train.predict(xgtrain, pred_leaf=True)\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "bst_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bst_train = xgb.train(param, xgtrain, num_trees, evals=watchlist) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正确率与模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T19:30:19.178182Z",
     "start_time": "2018-06-06T19:30:19.129338Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "training . . . \n",
      "cost time:116\n",
      "Train Accuary: 83.47%\n",
      "Train log_loss:  0.397309582592\n",
      "saved in:  ../data/project_2/models/Onehot_A/\n"
     ]
    }
   ],
   "source": [
    "FLAGS = flags('minitrain', 'Onehot_A')\n",
    "PARAMS = params('A_cat')  \n",
    "\n",
    "file_name = FLAGS.file_name\n",
    "onehot_name = PARAMS.onehot_name\n",
    "output_path = FLAGS.output_dir\n",
    "model_path = FLAGS.model_dir\n",
    "\n",
    "#导入数据\n",
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用\n",
    "xgtrain = xgb.DMatrix(X_train, label = y_train,)\n",
    "\n",
    "#设置参数, 开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "\n",
    "num_trees = 50\n",
    "deep = 9\n",
    "\n",
    "param = dict(\n",
    "        learning_rate =0.8, \n",
    "        booster='gbtree',\n",
    "        n_estimators=100,  \n",
    "        max_depth=deep, \n",
    "        min_child_weight=50,\n",
    "        gamma=0,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        colsample_bylevel=0.7,\n",
    "        objective= 'binary:logistic' ,\n",
    "        eta=0.4,\n",
    "        silent=0,\n",
    "        eval_metric='logloss',\n",
    "        seed=3)\n",
    "\n",
    "#调用cv函数\n",
    "#bst_train = xgb.cv(param, xgtrain, num_trees, nfold=3, stratified=True)\n",
    "bst_train = xgb.train(param, xgtrain, num_trees, ) \n",
    "#new_feature = bst_train.predict(xgtrain, pred_leaf=True)\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "\n",
    "train_preds = bst_train.predict(xgtrain)\n",
    "train_predictions = [round(value) for value in train_preds]\n",
    "y_train = xgtrain.get_label()\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "train_log_loss = log_loss(y_train, train_preds)\n",
    "print (\"Train log_loss: \" , train_log_loss)\n",
    "\n",
    "bst_train.save_model(model_path + 'tree{0}_deep{1}_{2}.xgboost'.format(num_trees, deep, onehot_name))\n",
    "print('saved in: ', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "training . . . \n",
      "cost time:33\n",
      "Train Accuary: 83.00%\n",
      "Train log_loss:  0.454812237607\n",
      "saved in:  ../data/project_2/models/Onehot_A/\n"
     ]
    }
   ],
   "source": [
    "FLAGS = flags('minitrain', 'Onehot_A')\n",
    "PARAMS = params('A_hour')  \n",
    "\n",
    "file_name = FLAGS.file_name\n",
    "onehot_name = PARAMS.onehot_name\n",
    "output_path = FLAGS.output_dir\n",
    "model_path = FLAGS.model_dir\n",
    "\n",
    "#导入数据\n",
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用\n",
    "xgtrain = xgb.DMatrix(X_train, label = y_train,)\n",
    "\n",
    "#设置参数, 开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "\n",
    "num_trees = 50\n",
    "deep = 9\n",
    "\n",
    "param = dict(\n",
    "        learning_rate =0.8, \n",
    "        booster='gbtree',\n",
    "        n_estimators=100,  \n",
    "        max_depth=deep, \n",
    "        min_child_weight=50,\n",
    "        gamma=0,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        colsample_bylevel=0.7,\n",
    "        objective= 'binary:logistic' ,\n",
    "        eta=0.4,\n",
    "        silent=0,\n",
    "        eval_metric='logloss',\n",
    "        seed=3)\n",
    "\n",
    "#调用cv函数\n",
    "#bst_train = xgb.cv(param, xgtrain, num_trees, nfold=3, stratified=True)\n",
    "bst_train = xgb.train(param, xgtrain, num_trees, ) \n",
    "#new_feature = bst_train.predict(xgtrain, pred_leaf=True)\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "\n",
    "train_preds = bst_train.predict(xgtrain)\n",
    "train_predictions = [round(value) for value in train_preds]\n",
    "y_train = xgtrain.get_label()\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "train_log_loss = log_loss(y_train, train_preds)\n",
    "print (\"Train log_loss: \" , train_log_loss)\n",
    "\n",
    "bst_train.save_model(model_path + 'tree{0}_deep{1}_{2}.xgboost'.format(num_trees, deep, onehot_name))\n",
    "print('saved in: ', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/project_2/output/Onehot_A/minitrain_X_A_xgb_all.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-27404d90b015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#导入数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Load Data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_npz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'{0}_X_{1}_all.npz'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monehot_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_npz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'{0}_y_{1}_all.npz'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monehot_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zhou/anaconda3/lib/python3.5/site-packages/scipy/sparse/_matrix_io.py\u001b[0m in \u001b[0;36mload_npz\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \"\"\"\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mPICKLE_KWARGS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mmatrix_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'format'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zhou/anaconda3/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/project_2/output/Onehot_A/minitrain_X_A_xgb_all.npz'"
     ]
    }
   ],
   "source": [
    "FLAGS = flags('minitrain', 'Onehot_A')\n",
    "PARAMS = params('A_xgb')  \n",
    "\n",
    "file_name = FLAGS.file_name\n",
    "onehot_name = PARAMS.onehot_name\n",
    "output_path = FLAGS.output_dir\n",
    "model_path = FLAGS.model_dir\n",
    "\n",
    "#导入数据\n",
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用\n",
    "xgtrain = xgb.DMatrix(X_train, label = y_train,)\n",
    "\n",
    "#设置参数, 开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "\n",
    "num_trees = 50\n",
    "deep = 9\n",
    "\n",
    "param = dict(\n",
    "        learning_rate =0.8, \n",
    "        booster='gbtree',\n",
    "        n_estimators=100,  \n",
    "        max_depth=deep, \n",
    "        min_child_weight=50,\n",
    "        gamma=0,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        colsample_bylevel=0.7,\n",
    "        objective= 'binary:logistic' ,\n",
    "        eta=0.4,\n",
    "        silent=0,\n",
    "        eval_metric='logloss',\n",
    "        seed=3)\n",
    "\n",
    "#调用cv函数\n",
    "#bst_train = xgb.cv(param, xgtrain, num_trees, nfold=3, stratified=True)\n",
    "bst_train = xgb.train(param, xgtrain, num_trees, ) \n",
    "#new_feature = bst_train.predict(xgtrain, pred_leaf=True)\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "\n",
    "train_preds = bst_train.predict(xgtrain)\n",
    "train_predictions = [round(value) for value in train_preds]\n",
    "y_train = xgtrain.get_label()\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "train_log_loss = log_loss(y_train, train_preds)\n",
    "print (\"Train log_loss: \" , train_log_loss)\n",
    "\n",
    "bst_train.save_model(model_path + 'tree{0}_deep{1}_{2}.xgboost'.format(num_trees, deep, onehot_name))\n",
    "print('saved in: ', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "training . . . \n",
      "cost time:18\n",
      "Train Accuary: 83.02%\n",
      "Train log_loss:  0.452250324549\n",
      "saved in:  ../data/project_2/models/Onehot_A/\n"
     ]
    }
   ],
   "source": [
    "FLAGS = flags('minitrain', 'Onehot_A')\n",
    "PARAMS = params('A_his')  \n",
    "\n",
    "file_name = FLAGS.file_name\n",
    "onehot_name = PARAMS.onehot_name\n",
    "output_path = FLAGS.output_dir\n",
    "model_path = FLAGS.model_dir\n",
    "\n",
    "#导入数据\n",
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用\n",
    "xgtrain = xgb.DMatrix(X_train, label = y_train,)\n",
    "\n",
    "#设置参数, 开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "\n",
    "num_trees = 50\n",
    "deep = 9\n",
    "\n",
    "param = dict(\n",
    "        learning_rate =0.8, \n",
    "        booster='gbtree',\n",
    "        n_estimators=100,  \n",
    "        max_depth=deep, \n",
    "        min_child_weight=50,\n",
    "        gamma=0,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        colsample_bylevel=0.7,\n",
    "        objective= 'binary:logistic' ,\n",
    "        eta=0.4,\n",
    "        silent=0,\n",
    "        eval_metric='logloss',\n",
    "        seed=3)\n",
    "\n",
    "#调用cv函数\n",
    "#bst_train = xgb.cv(param, xgtrain, num_trees, nfold=3, stratified=True)\n",
    "bst_train = xgb.train(param, xgtrain, num_trees, ) \n",
    "#new_feature = bst_train.predict(xgtrain, pred_leaf=True)\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "\n",
    "train_preds = bst_train.predict(xgtrain)\n",
    "train_predictions = [round(value) for value in train_preds]\n",
    "y_train = xgtrain.get_label()\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "train_log_loss = log_loss(y_train, train_preds)\n",
    "print (\"Train log_loss: \" , train_log_loss)\n",
    "\n",
    "bst_train.save_model(model_path + 'tree{0}_deep{1}_{2}.xgboost'.format(num_trees, deep, onehot_name))\n",
    "print('saved in: ', model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "training . . . \n",
      "cost time:38\n",
      "Train Accuary: 83.01%\n",
      "Train log_loss:  0.455020206432\n",
      "saved in:  ../data/project_2/models/Onehot_B/\n"
     ]
    }
   ],
   "source": [
    "FLAGS = flags('minitrain', 'Onehot_B')\n",
    "PARAMS = params('B_cat')  \n",
    "\n",
    "file_name = FLAGS.file_name\n",
    "onehot_name = PARAMS.onehot_name\n",
    "output_path = FLAGS.output_dir\n",
    "model_path = FLAGS.model_dir\n",
    "\n",
    "#导入数据\n",
    "print('Load Data')\n",
    "X_train = ss.load_npz(output_path+'{0}_X_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "\n",
    "y_train = ss.load_npz(output_path+'{0}_y_{1}_all.npz'.format(file_name, onehot_name), )\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "# 先转成np.array, 把数据类型转为np.float32(此时为2维数组shape(1,n)), 转为1-D np.arrar\n",
    "# 2维数组shape(m,n)适用于多分类问题, 在二分类中不适用\n",
    "xgtrain = xgb.DMatrix(X_train, label = y_train,)\n",
    "\n",
    "#设置参数, 开始训练\n",
    "start_time = time.time()\n",
    "print('training . . . ')\n",
    "\n",
    "num_trees = 50\n",
    "deep = 9\n",
    "\n",
    "param = dict(\n",
    "        learning_rate =0.8, \n",
    "        booster='gbtree',\n",
    "        n_estimators=100,  \n",
    "        max_depth=deep, \n",
    "        min_child_weight=50,\n",
    "        gamma=0,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        colsample_bylevel=0.7,\n",
    "        objective= 'binary:logistic' ,\n",
    "        eta=0.4,\n",
    "        silent=0,\n",
    "        eval_metric='logloss',\n",
    "        seed=3)\n",
    "\n",
    "#调用cv函数\n",
    "#bst_train = xgb.cv(param, xgtrain, num_trees, nfold=3, stratified=True)\n",
    "bst_train = xgb.train(param, xgtrain, num_trees, ) \n",
    "#new_feature = bst_train.predict(xgtrain, pred_leaf=True)\n",
    "print('cost time:{0}'.format(int(time.time() - start_time)))\n",
    "\n",
    "train_preds = bst_train.predict(xgtrain)\n",
    "train_predictions = [round(value) for value in train_preds]\n",
    "y_train = xgtrain.get_label()\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print (\"Train Accuary: %.2f%%\" % (train_accuracy * 100.0))\n",
    "train_log_loss = log_loss(y_train, train_preds)\n",
    "print (\"Train log_loss: \" , train_log_loss)\n",
    "\n",
    "bst_train.save_model(model_path + 'tree{0}_deep{1}_{2}.xgboost'.format(num_trees, deep, onehot_name))\n",
    "print('saved in: ', model_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 把生成好的.npz全部合并可以选择部分合并, \n",
    "# 把要合并的begin 放到 list(data_begins)中, \n",
    "# 如[0,200000,900000]做val, [100000,300000, . . . ]做训练, \n",
    "X_train, y_train = MergeNpz(output_path, file_name, data_begins, threshold,)\n",
    "y_train = y_train.toarray().astype(np.float32)[0]\n",
    "#X_val, y_val = MergeNpz(output_path, file_name, data_begins[-5:], threshold,)\n",
    "#y_val = y_val.toarray().astype(np.float32)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst_train = xgb.Booster(model_file= model_path + 'xgboost.model')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
